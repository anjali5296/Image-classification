{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_model_imagenet.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcHkbt-nGcwB",
        "colab_type": "code",
        "outputId": "96322c4a-d19b-4185-e14d-ef0e3ca224a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# prerequisites for imgaug library\n",
        "!pip install six numpy scipy Pillow matplotlib scikit-image opencv-python imageio Shapely"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.5.20)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (1.6.4.post2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (40.9.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image) (4.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSWEbEjyGl6b",
        "colab_type": "code",
        "outputId": "4a49a5b7-1b0a-4bd3-f802-b029ce779e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "# image augmentation library imgaug (https://github.com/aleju/imgaug)\n",
        "!pip install imgaug\n",
        "\n",
        "# NOTE: make sure to Restart Runtime after this installation completes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (0.2.8)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug) (2.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.4.5.20)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug) (3.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.11.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug) (1.6.4.post2)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug) (0.13.1)\n",
            "Collecting numpy>=1.15.0 (from imgaug)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.3MB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug) (2.3.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->imgaug) (0.46)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (1.0.2)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug) (2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (40.9.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug) (4.4.0)\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed numpy-1.16.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hqxH9zhGsdd",
        "colab_type": "code",
        "outputId": "33b7da58-c8f6-47da-a052-ddb2b4e221a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "# imgaug needs latest scikit module. so need to do this. else, will get some weird error related to numpy!\n",
        "!pip install --upgrade scikit-image\n",
        "\n",
        "# NOTE: make sure to Restart Runtime after this installation completes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-image\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/ab/674e168bf7d0bc597218b3bec858d02c23fbac9ec1fec9cad878c6cee95f/scikit_image-0.15.0-cp36-cp36m-manylinux1_x86_64.whl (26.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 26.3MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.2)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Collecting pillow>=4.3.0 (from scikit-image)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/c2/f84b1e57416755e967236468dcfb0fad7fd911f707185efc4ba8834a1a94/Pillow-6.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from PyWavelets>=0.4.0->scikit-image) (1.16.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (40.9.0)\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow, scikit-image\n",
            "  Found existing installation: Pillow 4.1.1\n",
            "    Uninstalling Pillow-4.1.1:\n",
            "      Successfully uninstalled Pillow-4.1.1\n",
            "  Found existing installation: scikit-image 0.13.1\n",
            "    Uninstalling scikit-image-0.13.1:\n",
            "      Successfully uninstalled scikit-image-0.13.1\n",
            "Successfully installed pillow-6.0.0 scikit-image-0.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cgkGszOGyNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imgaug import augmenters as iaa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDYfsbXiG7Br",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq = iaa.Sequential([iaa.Sometimes(0.5, iaa.SomeOf(3,[iaa.Fliplr(1.0),\n",
        "                                                    iaa.CoarseDropout(0.02, size_percent=0.05),\n",
        "                                                    iaa.AdditiveGaussianNoise(scale=(0, 0.05*255)),\n",
        "                                                    iaa.GaussianBlur(sigma=(0.0, 1.0)),\n",
        "                                                    iaa.Multiply((0.5, 1.5)),\n",
        "                                                    iaa.Affine(rotate=(-30, 30)),\n",
        "                                                    iaa.Sharpen(alpha=(0.0, 1.0), lightness=(0.75, 2.0)),\n",
        "                                                    iaa.Affine(scale=(0.5, 1.5))]))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BBrKLa36AoD",
        "colab_type": "text"
      },
      "source": [
        "***Eight Augmentations used***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scWpofZ3zcrv",
        "colab_type": "code",
        "outputId": "af89e126-1feb-4157-f32d-b9e4ae639127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib  inline\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "K.tensorflow_backend.set_session(tf.Session(config=config))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4-UL4Te0B0P",
        "colab_type": "code",
        "outputId": "d1bb8ee5-0b20-4261-ad2b-c1add956774a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5DThlzd0Ek2",
        "colab_type": "code",
        "outputId": "77465ab3-c2aa-4a4f-c853-6d1ae9c51efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls\n",
        "!unzip -qq 'gdrive/My Drive/Colab Notebooks/Assg4/tiny-imagenet-200.zip'\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n",
            "gdrive\tsample_data  tiny-imagenet-200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cqs6IYd0HoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
        "val_data.head(3)\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    preprocessing_function=seq.augment_image\n",
        "    )\n",
        "\n",
        "valid_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV4US41kC3D6",
        "colab_type": "code",
        "outputId": "c5890a12-f5f8-44fe-f89e-99b9378be5eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_generator.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(64, 64), color_mode='rgb', \n",
        "                                                    batch_size=64, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQC86JqfC5mJ",
        "colab_type": "code",
        "outputId": "72b4112f-53c5-4928-890b-c7724d6f13ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = valid_generator.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(64, 64),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=512, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taYwP-HD0UHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import six\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    Dense,\n",
        "    Flatten,\n",
        "    GlobalAveragePooling2D,\n",
        "    Dropout\n",
        ")\n",
        "from keras.layers.convolutional import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    AveragePooling2D,\n",
        "    SeparableConv2D\n",
        ")\n",
        "from keras.layers.merge import add\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "#from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko2Jv0zJ0cyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _bn_relu(input):\n",
        "    \"\"\"Helper to build a BN -> relu block\n",
        "    \"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "    return Activation(\"relu\")(norm)\n",
        "  \n",
        "  \n",
        "def _conv_bn_relu(**conv_params):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu block\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        conv = SeparableConv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "  \n",
        "  \n",
        "def _bn_relu_conv(**conv_params):\n",
        "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return SeparableConv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(activation)\n",
        "\n",
        "    return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDksWZB70mTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _shortcut(input, residual):\n",
        "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "    \"\"\"\n",
        "    # Expand channels of shortcut to match residual.\n",
        "    # Stride appropriately to match residual (width, height)\n",
        "    # Should be int if network architecture is correctly configured.\n",
        "    input_shape = K.int_shape(input)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    #print(input_shape, residual_shape )\n",
        "    #stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "    #stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "   \n",
        "    shortcut = input\n",
        "    # 1 X 1 conv if shape is different. Else identity.\n",
        "    if not equal_channels:\n",
        "        shortcut = SeparableConv2D(filters=residual_shape[CHANNEL_AXIS],  #1x1 used to increase channels, as same number of channels are required for adding two layers\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(1,1),\n",
        "                          padding=\"valid\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.0001))(input)\n",
        "\n",
        "    return add([shortcut, residual])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6HBsPOW00Cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
        "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        for i in range(repetitions):\n",
        "            #print(\"r\",i)\n",
        "            init_strides = (1, 1)\n",
        "            if i == 0 and not is_first_layer:\n",
        "                init_strides = (1, 1)\n",
        "            input = block_function(filters=filters, init_strides=init_strides,\n",
        "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
        "        return input\n",
        "\n",
        "    return f\n",
        "  \n",
        "  \n",
        "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv1 = SeparableConv2D(filters=filters, kernel_size=(3, 3),\n",
        "                           strides=init_strides,\n",
        "                           padding=\"same\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
        "                                  strides=init_strides)(input)\n",
        "\n",
        "        #conv1 = Dropout(0.2)(conv1)\n",
        "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
        "        #print(\"basic \", K.int_shape(input), K.int_shape(residual))\n",
        "        #return residual\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwC_dv_91B2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _handle_dim_ordering():\n",
        "    global ROW_AXIS\n",
        "    global COL_AXIS\n",
        "    global CHANNEL_AXIS\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        ROW_AXIS = 1\n",
        "        COL_AXIS = 2\n",
        "        CHANNEL_AXIS = 3\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        ROW_AXIS = 2\n",
        "        COL_AXIS = 3\n",
        "        \n",
        "        \n",
        "def _get_block(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKYwEdO-1KF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Builder(object):\n",
        "    @staticmethod\n",
        "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras `Model`.\n",
        "        \"\"\"\n",
        "        _handle_dim_ordering()\n",
        "        if len(input_shape) != 3:\n",
        "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
        "\n",
        "        # Permute dimension order if necessary\n",
        "        if K.image_dim_ordering() == 'tf':\n",
        "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
        "\n",
        "        # Load function from str if needed.\n",
        "        block_fn = _get_block(block_fn)\n",
        "        \n",
        "        filters = 32\n",
        "\n",
        "        input = Input(shape=input_shape)\n",
        "        conv1 = Conv2D(filters, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False, kernel_regularizer = l2(1.e-4))(input)\n",
        "        #conv1 = _conv_bn_relu(filters=filters, kernel_size=(3, 3), strides=(2, 2))(input)\n",
        "        conv1_br = _bn_relu(conv1)\n",
        "        conv2 = _conv_bn_relu(filters=filters, kernel_size=(3, 3), strides=(1, 1))(conv1_br)\n",
        "        conv3 = _conv_bn_relu(filters=filters, kernel_size=(3, 3), strides=(1, 1))(conv2)\n",
        "        #pool1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(conv3)\n",
        "        #pool1 = Dropout(0.2)(conv3)\n",
        "\n",
        "        block = conv3\n",
        "        filters = 128\n",
        "        for i, r in enumerate(repetitions):\n",
        "            #print(i, K.int_shape(block), K.int_shape(input), filters)\n",
        "            #print(\"i\",i)\n",
        "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
        "            if i != 2:\n",
        "              block = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(block)\n",
        "              filters *= 4\n",
        "            #print(i, K.int_shape(block), K.int_shape(input), filters)\n",
        "           # print(filters)\n",
        "\n",
        "        # Last activation\n",
        "        block = _bn_relu(block)\n",
        "\n",
        "        # Classifier block\n",
        "        block_shape = K.int_shape(block)\n",
        "        block = Conv2D(num_outputs, (1,1), strides=(1,1), padding='same', name='before_flatten', use_bias=False)(block)\n",
        "        pool2 = GlobalAveragePooling2D()(block)\n",
        "        #flatten1 = Flatten()(pool2)\n",
        "        #dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
        "                      #activation=\"softmax\")(flatten1)\n",
        "\n",
        "        out = Activation('softmax')(pool2)\n",
        "        model = Model(inputs=input, outputs=out)\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_model(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr0GgRqA4jx-",
        "colab_type": "code",
        "outputId": "206ad92d-165c-4183-e48e-717835ddb503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model = Builder.build_model((3, None, None), 200)\n",
        "#print(filters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRS6xo6r4rEz",
        "colab_type": "code",
        "outputId": "f42c207b-075e-4636-a8a8-9d3533ce83ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2278
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, None, None, 3 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 3 128         conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, None, None, 3 1344        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 3 128         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, None, None, 3 1344        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 3 128         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, None, None, 3 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, None, None, 1 4512        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 1 512         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, None, None, 1 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, None, None, 1 4256        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, None, None, 1 17664       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 1 0           separable_conv2d_5[0][0]         \n",
            "                                                                 separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 1 512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, None, None, 1 17664       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 1 512         separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, None, None, 1 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, None, None, 1 17664       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 1 0           add_1[0][0]                      \n",
            "                                                                 separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 1 512         max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, None, None, 5 67200       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 5 2048        separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, None, None, 5 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, None, None, 5 66176       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, None, None, 5 267264      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 5 0           separable_conv2d_10[0][0]        \n",
            "                                                                 separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 5 2048        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, None, None, 5 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, None, None, 5 267264      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 5 2048        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, None, None, 5 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, None, None, 5 267264      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 5 0           add_3[0][0]                      \n",
            "                                                                 separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 5 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 5 2048        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, None, None, 5 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_13 (SeparableC (None, None, None, 2 1055232     activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 2 8192        separable_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, None, None, 2 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_15 (SeparableC (None, None, None, 2 1051136     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_14 (SeparableC (None, None, None, 2 4214784     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 2 0           separable_conv2d_15[0][0]        \n",
            "                                                                 separable_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 2 8192        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, None, None, 2 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_16 (SeparableC (None, None, None, 2 4214784     activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 2 8192        separable_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, None, None, 2 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_17 (SeparableC (None, None, None, 2 4214784     activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n",
            "                                                                 separable_conv2d_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 2 8192        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, None, None, 2 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "before_flatten (Conv2D)         (None, None, None, 2 409600      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 200)          0           before_flatten[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 200)          0           global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 16,204,192\n",
            "Trainable params: 16,182,496\n",
            "Non-trainable params: 21,696\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC0xItVA5A1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-gtPizY5HZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import *\n",
        "filepath = \"/content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m.hdf5\"\n",
        "checkpoint = [ModelCheckpoint(filepath, period = 1, monitor='val_acc', verbose=1,save_weights_only=True, save_best_only=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDcJSThp5Udz",
        "colab_type": "code",
        "outputId": "c84a5646-26e6-4a82-8023-b9e0d0adb6c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    callbacks=checkpoint,\n",
        "                    epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/5\n",
            "390/390 [==============================] - 745s 2s/step - loss: 4.0411 - acc: 0.1410 - val_loss: 6.2002 - val_acc: 0.0627\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.06271, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m.hdf5\n",
            "Epoch 2/5\n",
            "390/390 [==============================] - 729s 2s/step - loss: 3.1260 - acc: 0.2865 - val_loss: 4.6728 - val_acc: 0.1105\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.06271 to 0.11046, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m.hdf5\n",
            "Epoch 3/5\n",
            "390/390 [==============================] - 721s 2s/step - loss: 2.6258 - acc: 0.3783 - val_loss: 4.3594 - val_acc: 0.1203\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.11046 to 0.12026, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m.hdf5\n",
            "Epoch 4/5\n",
            "390/390 [==============================] - 719s 2s/step - loss: 2.2543 - acc: 0.4496 - val_loss: 4.0648 - val_acc: 0.1656\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.12026 to 0.16558, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m.hdf5\n",
            "Epoch 5/5\n",
            "390/390 [==============================] - 718s 2s/step - loss: 1.8824 - acc: 0.5275 - val_loss: 4.4441 - val_acc: 0.1384\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.16558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa683434438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaJBXd2jFT86",
        "colab_type": "code",
        "outputId": "df46688d-7c86-4876-8b13-1b1707a88349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    callbacks=checkpoint,\n",
        "                    epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "390/390 [==============================] - 275s 706ms/step - loss: 3.1496 - acc: 0.2866 - val_loss: 5.7871 - val_acc: 0.0518\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.16558\n",
            "Epoch 2/5\n",
            "390/390 [==============================] - 271s 695ms/step - loss: 2.5025 - acc: 0.4000 - val_loss: 5.6149 - val_acc: 0.0522\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.16558\n",
            "Epoch 3/5\n",
            "390/390 [==============================] - 270s 692ms/step - loss: 1.9873 - acc: 0.5022 - val_loss: 6.2201 - val_acc: 0.0417\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.16558\n",
            "Epoch 4/5\n",
            "390/390 [==============================] - 270s 692ms/step - loss: 1.4364 - acc: 0.6257 - val_loss: 7.9510 - val_acc: 0.0296\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.16558\n",
            "Epoch 5/5\n",
            "390/390 [==============================] - 270s 691ms/step - loss: 0.8262 - acc: 0.7774 - val_loss: 7.7326 - val_acc: 0.0413\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.16558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa6812dd470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QDxRGdCK5aN",
        "colab_type": "code",
        "outputId": "1ffeea19-09fd-4b7c-9885-40aa975f5b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    callbacks=checkpoint,\n",
        "                    epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1562/1562 [==============================] - 3037s 2s/step - loss: 2.4521 - acc: 0.4166 - val_loss: 2.6662 - val_acc: 0.3917\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.16558 to 0.39165, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m.hdf5\n",
            "Epoch 2/10\n",
            "1562/1562 [==============================] - 3044s 2s/step - loss: 1.7677 - acc: 0.5562 - val_loss: 2.4124 - val_acc: 0.4317\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.39165 to 0.43170, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m.hdf5\n",
            "Epoch 3/10\n",
            "1562/1562 [==============================] - 3123s 2s/step - loss: 1.3799 - acc: 0.6418 - val_loss: 2.2364 - val_acc: 0.4816\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.43170 to 0.48156, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m.hdf5\n",
            "Epoch 4/10\n",
            "1562/1562 [==============================] - 3083s 2s/step - loss: 0.9964 - acc: 0.7310 - val_loss: 2.3172 - val_acc: 0.4859\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.48156 to 0.48588, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m.hdf5\n",
            "Epoch 5/10\n",
            "1562/1562 [==============================] - 3048s 2s/step - loss: 0.6257 - acc: 0.8264 - val_loss: 2.7324 - val_acc: 0.4564\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.48588\n",
            "Epoch 6/10\n",
            "1562/1562 [==============================] - 3044s 2s/step - loss: 0.3667 - acc: 0.8954 - val_loss: 3.1103 - val_acc: 0.4524\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.48588\n",
            "Epoch 7/10\n",
            "1562/1562 [==============================] - 3030s 2s/step - loss: 0.2671 - acc: 0.9215 - val_loss: 2.7881 - val_acc: 0.4706\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.48588\n",
            "Epoch 8/10\n",
            "1562/1562 [==============================] - 3024s 2s/step - loss: 0.2247 - acc: 0.9333 - val_loss: 3.4888 - val_acc: 0.4369\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.48588\n",
            "Epoch 9/10\n",
            "1562/1562 [==============================] - 3038s 2s/step - loss: 0.1877 - acc: 0.9440 - val_loss: 3.4708 - val_acc: 0.4533\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.48588\n",
            "Epoch 10/10\n",
            "1562/1562 [==============================] - 3033s 2s/step - loss: 0.1709 - acc: 0.9485 - val_loss: 3.1712 - val_acc: 0.4779\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.48588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa6812dd3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM6vXWF1CbpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import *\n",
        "filepath = \"/content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m_aug.hdf5\"\n",
        "checkpoint = [ModelCheckpoint(filepath, period = 1, monitor='val_acc', verbose=1,save_weights_only=True, save_best_only=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYvSVTYd5XT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.models import load_weights\n",
        "model.load_weights(\"/content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m.hdf5\", by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Rg2G11BFHR",
        "colab_type": "code",
        "outputId": "7c65a2d9-2d7d-4d4c-da74-d3ea5c9cd807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    callbacks=checkpoint,\n",
        "                    epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/5\n",
            "390/390 [==============================] - 760s 2s/step - loss: 2.0992 - acc: 0.4909 - val_loss: 2.9954 - val_acc: 0.3293\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.32926, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m_aug.hdf5\n",
            "Epoch 2/5\n",
            "390/390 [==============================] - 743s 2s/step - loss: 1.5529 - acc: 0.6048 - val_loss: 3.3185 - val_acc: 0.2941\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.32926\n",
            "Epoch 3/5\n",
            "390/390 [==============================] - 735s 2s/step - loss: 1.2286 - acc: 0.6797 - val_loss: 3.2307 - val_acc: 0.3231\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.32926\n",
            "Epoch 4/5\n",
            "390/390 [==============================] - 735s 2s/step - loss: 0.9880 - acc: 0.7413 - val_loss: 3.2592 - val_acc: 0.3142\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.32926\n",
            "Epoch 5/5\n",
            "390/390 [==============================] - 735s 2s/step - loss: 0.8084 - acc: 0.7878 - val_loss: 3.4357 - val_acc: 0.3119\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.32926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f886f1d63c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSaTAPYRR3tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import *\n",
        "filepath = \"/content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m_aug.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, period = 1, monitor='val_acc', verbose=1,save_weights_only=True, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dkLnD6HQzy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3YyoA44RA7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
        "                              patience=2, min_lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LaxBd5rRh27",
        "colab_type": "code",
        "outputId": "aed51188-8146-41bb-c3a0-070524a1a7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    callbacks=[checkpoint,reduce_lr],\n",
        "                    epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "390/390 [==============================] - 353s 904ms/step - loss: 2.6294 - acc: 0.3776 - val_loss: 5.4215 - val_acc: 0.0851\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.08512, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m_aug.hdf5\n",
            "Epoch 2/5\n",
            "390/390 [==============================] - 339s 869ms/step - loss: 1.9449 - acc: 0.5114 - val_loss: 5.8040 - val_acc: 0.0809\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.08512\n",
            "Epoch 3/5\n",
            "390/390 [==============================] - 331s 848ms/step - loss: 1.5439 - acc: 0.6034 - val_loss: 6.5448 - val_acc: 0.0716\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.08512\n",
            "Epoch 4/5\n",
            "390/390 [==============================] - 338s 866ms/step - loss: 1.2205 - acc: 0.6853 - val_loss: 6.9621 - val_acc: 0.0772\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.08512\n",
            "Epoch 5/5\n",
            "390/390 [==============================] - 324s 830ms/step - loss: 0.9816 - acc: 0.7461 - val_loss: 6.7158 - val_acc: 0.0839\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.08512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f886936dac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxDf9WkKYuNl",
        "colab_type": "code",
        "outputId": "f44a37ae-3aa8-4894-8cf6-f6ee07b3955d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1492
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    callbacks=[checkpoint,reduce_lr],\n",
        "                    epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1562/1562 [==============================] - 3128s 2s/step - loss: 1.5639 - acc: 0.5975 - val_loss: 2.2390 - val_acc: 0.5026\n",
            "\n",
            "Epoch 00001: val_acc improved from 0.08512 to 0.50257, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m_aug.hdf5\n",
            "Epoch 2/10\n",
            "1562/1562 [==============================] - 3147s 2s/step - loss: 0.9879 - acc: 0.7365 - val_loss: 2.3136 - val_acc: 0.5091\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.50257 to 0.50906, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m_aug.hdf5\n",
            "Epoch 3/10\n",
            "1562/1562 [==============================] - 3140s 2s/step - loss: 0.7730 - acc: 0.7890 - val_loss: 2.3389 - val_acc: 0.5218\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.50906 to 0.52182, saving model to /content/gdrive/My Drive/Colab Notebooks/Assg4/assg4_11_16m_aug.hdf5\n",
            "Epoch 4/10\n",
            "1562/1562 [==============================] - 3124s 2s/step - loss: 0.6228 - acc: 0.8279 - val_loss: 2.5758 - val_acc: 0.5052\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.52182\n",
            "Epoch 5/10\n",
            "1562/1562 [==============================] - 3112s 2s/step - loss: 0.5493 - acc: 0.8463 - val_loss: 2.5533 - val_acc: 0.5139\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.52182\n",
            "Epoch 6/10\n",
            "1562/1562 [==============================] - 3141s 2s/step - loss: 0.4693 - acc: 0.8673 - val_loss: 2.6496 - val_acc: 0.5199\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.52182\n",
            "Epoch 7/10\n",
            " 218/1562 [===>..........................] - ETA: 43:50 - loss: 0.3551 - acc: 0.9009"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-f5f0ee270fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     epochs=10)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLNP6DOK6wr_",
        "colab_type": "text"
      },
      "source": [
        "***Best accuracy achieved(after applying augmentaion and ReduceLROnPlateau) =  52.182***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVRz1oX6iss1",
        "colab_type": "code",
        "outputId": "922fd4df-4adb-48ec-e0e9-e9d347debea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git \n",
        "import keras_contrib\n",
        "from keras_contrib.callbacks.cyclical_learning_rate import CyclicLR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-8u6vrlac\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.11.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.9)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.16.2)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-v5w5k9_v/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw0WrrbSj0Vd",
        "colab_type": "code",
        "outputId": "ad4f56e8-935c-47fd-8bca-5b3d053b6573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "cyclic = CyclicLR(base_lr=1e-4, max_lr=0.05, step_size=4000, mode='triangular')\n",
        "model.fit_generator(train_generator, epochs=10, steps_per_epoch=800, validation_steps=40, validation_data=validation_generator, callbacks = [checkpoint, cyclic]) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 1758s 2s/step - loss: 1.9684 - acc: 0.5236 - val_loss: 4.6034 - val_acc: 0.1755\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.52182\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 1756s 2s/step - loss: 2.6624 - acc: 0.3748 - val_loss: 4.0501 - val_acc: 0.2283\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.52182\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 1759s 2s/step - loss: 2.8150 - acc: 0.3505 - val_loss: 5.5032 - val_acc: 0.1284\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.52182\n",
            "Epoch 4/10\n",
            "292/800 [=========>....................] - ETA: 16:36 - loss: 2.9157 - acc: 0.3333"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBVisU9q63Uv",
        "colab_type": "text"
      },
      "source": [
        "***Applied cycliclr***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGgb-VWc68km",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "***Best accuracy achieved(after applying augmentaion and ReduceLROnPlateau) = 52.182, Eight Augmentations used***"
      ]
    }
  ]
}